The aim of physics is to uncover the underlying principles governing natural phenomena. These laws are articulated through theoretical models, often in mathematical terms (such as Newtonâ€™s law of gravitation), and must be tested against experimental or observational evidence (for instance, measuring how long it takes for an apple to fall). A crucial aspect of physics involves quantitatively comparing these theoretical models with empirical data and measurements through statistical analysis. 

The primary goal of this thesis is to enable new physics discoveries by addressing the statistical and computational challenges that arise in the fields of astrophysics and cosmology. 
Traditional methods in modern astrophysical data analysis are sampling-based inference techniques like Markov-chain Monte Carlo and nested sampling methods. However, these approaches frequently rely on approximate likelihoods and suffer from a significant drawback: the time required to achieve convergence scales poorly with the dimensionality of the explored parameter space. To overcome these limitations, this thesis contributes to develop and establish an alternative approach based on novel simulation-based inference (\gls*{sbi}) techniques, that have seen a remarkable development in recent years. 

We began in Chapter~\ref{cha:sbi} by outlining the landscape of \gls*{sbi} approaches, including traditional ones, such as approximate Bayesian computation. We then detailed the various neural \gls*{sbi} algorithms, neural posterior estimation and neural likelihood estimation, and especially focused on truncated marginal neural ratio estimation (\gls*{tmnre}), the main inference algorithm employed throughout this thesis. \Gls*{tmnre} builds on three key ingredients: neural ratio estimation via classification, marginalization, and prior truncation. We then emphasized its different advantages and pitfalls with respect to the others \gls*{sbi} methods, and discussed testing strategies.

We first applied \gls*{tmnre} in Chapter~\ref{cha:lensing}, to the analysis of strong lensing images as a dark matter probe. Starting with an overview of strong lensing and its potential to probe dark matter substructures, we discussed the modeling complexities involved, including lens and source parameter uncertainties, and how to model populations of substructures from different dark matter scenarios. We developed a \gls*{sbi} pipeline to infer the cutoff mass in the dark matter halo mass function directly from simulated observations. Our results demonstrated that \gls*{tmnre} enables precise marginal and targeted inference, overcoming traditional computational challenges. We further showed the application of hierarchical inference to extract the dark matter cutoff mass signal from a dataset of lenses, paving the way for future advancements in dark matter characterization using strong lensing observations.

We then extended the \gls*{tmnre} framework in Chapter~\ref{cha:anre}, where we proposed two new technical building blocks. First we developed autoregressive ratio estimation with the aim to robustly estimate correlated high-dimensional posteriors. Second, we proposed a slice-based nested sampling algorithm to efficiently draw both posterior samples and constrained prior samples from ratio estimators, the latter being instrumental for sequential inference.  

In Chapter~\ref{cha:cosmo}, we tackled the inverse problem that goes from non-linear, non-local mappings of late-time density fields to Gaussian cosmological initial conditions. To this end, we employed autoregressive Gaussian likelihood estimation to model the conditional dependencies between pixels in the density field. Posterior sampling is achieved through a Gibbs sampling algorithm based on exact data augmentation, ensuring efficient exploration of high-dimensional parameter spaces. The proposed approach combines computational efficiency with applicability to generic, non-differentiable forward simulators, making it suitable for broader astrophysical and cosmological data analysis tasks.

Finally, in Chapter~\ref{cha:detection}, we turned towards the problem of point source detection and population parameter inference in sky-maps. We developed a highly interpretable (since it resembles components of traditional survey analysis workflows) \gls*{sbi} framework that allows, for the first time to the authors' knowledge, to perform consistently point source detection and population parameters inference, from both detected and sub-threshold. This was possible by defining source detection as a novel and high-dimensional form of prior truncation to incorporate detected sources into the simulation model.

Overall, this thesis aimed to highlight the potential of \gls*{sbi} for astrophysical data analysis, positioning this framework as an essential part of the modern physics data analysis toolkit.
